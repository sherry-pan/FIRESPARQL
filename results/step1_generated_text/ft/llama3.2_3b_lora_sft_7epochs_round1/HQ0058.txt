Question:
What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request? 

Generated SPARQL:
 SELECT?metric?metric_lbl (AVG(?value) AS?average)
     WHERE {
        ?dataset       a                orkgc:Dataset;
                     rdfs:label      ?dataset_lbl.
         FILTER(REGEX(?dataset_lbl, "feature request"))
        ?benchmark      orkgp:HAS_DATASET      ?dataset;
                        orkgp:HAS_EVALUATION   ?eval.
        ?eval           orkgp:HAS_VALUE        ?value.
         OPTIONAL {?eval           orkgp:HAS_METRIC        ?metric.
                 ?metric          rdfs:label              ?metric_lbl.}
        ?model         orkgp:HAS_BENCHMARK     ?benchmark;
                        orkgp:HAS_SOURCE_CODE   ?sourcecode;
                        orkgp:HAS_MODEL         ?model.
        ?sourcecode   orkgp:HAS_MODEL         ?model;
                      orkgp:HASTeknik        ?teknik.
        ?model       orkgp:HAS_TEKNIK         ?teknik.
         FILTER(REGEX(?teknik, "machine learning"))
        ?model         orkgp:HAS_ALGORITHM     ?algorithm.
         OPTIONAL {?algorithm      rdfs:label              ?algorithm_lbl.
                 ?algorithm      orkgp:HAS_DATASET      ?dataset.
                 ?dataset       orkgp:HAS_FEATURE_SET   ?featureset.
                 ?featureset     orkgp:HAS_MODEL         ?model.
                 ?model         orkgp:HAS_FEATURE        ?feature.
                 ?feature      rdfs:label              ?feature_lbl.
                 ?feature      orkgp:HAS_VALUE        ?value.
                 ?value       orkgp:HAS
