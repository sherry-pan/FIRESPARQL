Question:
What is the best performing model benchmarking the BUCC German-to-English dataset in terms of F1 score metric?

Generated SPARQL:
 PREFIX orkg: <http://www.openresearchknowledgegraph.org/ontology/>
     PREFIX owl: <http://www.w3.org/ontology/>
     SELECT?model?metric
     WHERE {
       ?model a orkg:Model.
       ?model orkg:hasBenchmark?benchmark.
       ?benchmark a orkg:BenchMark.
       ?benchmark orkg:hasMetric?metric.
       ?benchmark orkg:hasDataset?dataset.
       ?dataset orkg:hasDatasetName "BUCC".
       ?dataset orkg:hasDatasetLanguage "German".
       ?dataset orkg:hasDatasetTargetLanguage "English".
       ?benchmark orkg:hasMetric?metric.
       ?benchmark orkg:hasMetric?metric2.
        FILTER (STRFTER(?metric,?metric2) && STRIF(?metric,?metric2))
        FILTER (STRFTER(?metric,?f1score) && STRIF(?metric,?f1score))
       ?model orkg:hasMetric?metric.
       ?model orkg:hasMetric?f1score.
       ?f1score a orkg:F1Score.
       ?f1score owl:hasValue "0.95".
       ?f1score owl:hasUnit "F1 score".
       ?f1score owl:hasMetric?metric.
       ?f1score owl:hasMetric?metric2.
        FILTER (STRIF(?f1score,?metric) && STRIF(?f1score,?metric2))
    } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END { } 
    END
