{
"question": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?",
"extracted\_terms": {
"evaluation metrics",
"benchmarking models",
"MLDoc Zero-Shot English-to-Italian dataset"
},
"candidates": {
"evaluation metrics": [
{
"uri": "orkgp:HAS_EVALUATION_METRIC",
"rdfs:label": "BLEU",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_EVALUATION_METRIC",
"rdfs:label": "ROUGE",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_EVALUATION_METRIC",
"rdfs:label": "METEOR",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_EVALUATION_METRIC",
"rdfs:label": "TER",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_EVALUATION_METRIC",
"rdfs:label": "CIDEr",
"rdf:type": "orkgp:Predicate"
}
],
"benchmarking models": [
{
"uri": "orkgp:HAS_BENCHMARK",
"rdfs:label": "Benchmark",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_EVALUATION",
"rdfs:label": "Evaluation",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_MODEL",
"rdfs:label": "Model",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_PERFORMANCE",
"rdfs:label": "Performance",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_TEST",
"rdfs:label": "Test",
"rdf:type": "orkgp:Predicate"
}
],
"MLDoc Zero-Shot English-to-Italian dataset": [
{
"uri": "orkgr:R122689",
"rdfs:label": "MLDoc",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgr:R122689",
"rdfs:label": "MLDoc",
"rdf:type": "orkgc:Dataset"
},
{
"uri": "orkgr:R122689",
"rdfs:label": "Zero-Shot",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgr:R122689",
"rdfs:label": "English-to-Italian",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgp:HAS_DATASET",
"rdfs:label": "Dataset",
"rdf:type": "orkgp:Predicate"
}
]
}
}