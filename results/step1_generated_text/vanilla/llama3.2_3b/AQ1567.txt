Question:
What is the best performing model benchmarking the CoNLL++ dataset in terms of F1 metric?

Generated SPARQL:
 PREFIX orkg: <http://example.org/orkg/>
     PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
     PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
     PREFIXowl: <http://www.w3.org/2002/07/owl#>
     PREFIX foaf: <http://xmlns.com/foaf/0.1/>
     PREFIX schema: <http://schema.org/>
     PREFIX dbpedia: <http://dbpedia.org/ontology/>
     PREFIX dbpedia-labs: <http://dbpedia-labs.org/ontology/>
     PREFIX orkg-labs: <http://example.org/orkg-labs/>
     PREFIX orkg-projects: <http://example.org/orkg-projects/>
     PREFIX orkg-results: <http://example.org/orkg-results/>

     SELECT?model?f1
     WHERE {
        ?project a orkg:Project.
        ?project schema:hasDataset?dataset.
        ?dataset a orkg:Dataset.
        ?dataset schema:hasBenchmark?benchmark.
        ?benchmark schema:hasMetric?metric.
        ?metric schema:hasValue?f1.
        ?project orkg:hasModel?model.
         FILTER (str(?metric) = "F1")
         FILTER (str(?dataset) = "CoNLL++")
         FILTER (MAX(?f1) = (SELECT MAX(?f1) WHERE {?model orkg:hasBenchmark?benchmark.?benchmark schema:hasMetric?metric.?metric schema:hasValue?f1. })))
     } 
     GROUP BY?model?f1 
     HAVING COUNT(?model) > 1 
     ORDER BY DESC(?f1) 
     LIMIT 1 
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END
    END

