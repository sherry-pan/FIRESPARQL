Question:
What evaluation metrics are commonly used when benchmarking models on the SQuAD2.0 dataset?

Generated SPARQL:
 SELECT DISTINCT?metric?metric_lbl
     WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label      ?dataset_lbl.
       FILTER (str(?dataset_lbl) = "SQuAD2.0")
      ?benchmark      orkgp:HAS_DATASET      ?dataset;
                      orkgp:HAS_BENCHMARK     ?benchmark.
      ?metric         orkgp:HAS_EVALUATION  ?eval;
                      orkgp:P7032           ?cont.
      ?cont           rdfs:label              ?metric_lbl.
      ?eval           orkgp:P7031           ?eval_metric.
       FILTER (str(?eval_metric) = "Accuracy" || str(?eval_metric) = "macro-F1" || str(?eval_metric) = "Recall")
     }<|eot_id|>
