Question:
What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Berzerk dataset?

Generated SPARQL:
 SELECT DISTINCT?metric,?metric_lbl
     WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label      ?dataset_lbl.
       FILTER (str(?dataset_lbl) = "Atari 2600 Berzerk")
      ?benchmark      orkgp:HAS_DATASET      ?dataset;
                      orkgp:HAS_EVALUATION   ?eval.
      ?eval           orkgp:HAS_METRIC        ?metric;
                      orkgp:HAS_VALUE         ?value.
      ?metric         rdfs:label              ?metric_lbl.
      ?cont          orkgp:HAS_BENCHMARK     ?benchmark.
     }     ORDER BY DESC(?value) LIMIT 10. 
    SELECT DISTINCT?metric,?metric_lbl
    WHERE {
     ?cont      orkgp:HAS_EVALUATION      ?eval.
     ?eval      rdfs:label                ?eval_lbl.
      FILTER (str(?eval_lbl) = "accuracy")
     ?cont      orkgp:HAS_BENCHMARK      ?benchmark.
     ?benchmark  rdfs:label                ?benchmark_lbl.
      FILTER (str(?benchmark_lbl) = "Atari 2600 Berzerk")
     ?cont      orkgp:HAS_DATASET        ?dataset.
     ?dataset   rdfs:label                ?dataset_lbl.
     ?metric    orkgp:HAS_METRIC         ?metric.
     ?metric    rdfs:label                ?metric_lbl.
    }     ORDER BY DESC(?eval_lbl.value) LIMIT 10. 
    SELECT DISTINCT?metric,?metric_lbl
    WHERE {
     ?cont      orkgp:HAS_EVALUATION      ?eval.
     ?eval      rdfs:label                ?eval_lbl.
      FILTER (str(?eval_lbl) = "F1-score")
     ?cont      orkgp:HAS_BENCHMARK      ?benchmark.
     ?benchmark  rdfs:label                ?benchmark_lbl.
      FILTER (str(?benchmark_lbl) = "Atari 2600 Berkerk")
     ?cont      orkgp:HAS_DATASET        ?dataset.
     ?dataset   rdfs:label                ?dataset_lbl.
     ?metric    orkgp:HAS_METRIC         ?metric.
     ?metric    rdfs:label                ?metric_lbl.
    }     ORDER BY DESC(?eval_lbl.value) LIMIT 10. 
    SELECT DISTINCT?metric,?metric_lbl
    WHERE {
     ?cont      orkgp:HAS_EVALUATION      ?eval.
     ?eval      rdfs:label                ?eval_lbl.
      FILTER (str(?eval_lbl) = "F1-score")
     ?cont      orkgp:HAS_BENCHMARK      ?benchmark.
     ?benchmark  rdfs:label                ?benchmark_lbl.
      FILTER (str(?benchmark_lbl) = "Atari 2600 Berkerk")
     ?cont      orkgp:HAS_DATASET        ?dataset.
     ?dataset   rdfs:label                ?dataset_lbl.
     ?metric    orkgp:HAS_METRIC         ?metric.
     ?metric    rdfs:label                ?metric_lbl.
    }     ORDER BY DESC(?eval_lbl.value) LIMIT 10. 
    SELECT DISTINCT?metric,?metric_lbl
    WHERE {
     ?cont      orkgp:HAS_EVALUATION      ?eval.
     ?eval      rdfs:label                ?eval_lbl.
      FILTER (str(?eval_lbl) = "accuracy")
     ?cont      orkgp:HAS_BENCHMARK      ?benchmark.
     ?benchmark  rdfs:label                ?benchmark_lbl.
      FILTER (str(?benchmark_lbl) = "Atari 2600 Berkerk")
     ?cont      orkgp:HAS_DATASET        ?dataset.
     ?dataset   rdfs:label                ?dataset_lbl.
     ?metric    orkgp:HAS_METRIC         ?metric.
     ?metric    rdfs:label                ?metric_lbl.
    }     ORDER BY DESC(?eval_lbl.value) LIMIT 10. 
    SELECT DISTINCT?metric,?metric_lbl
    WHERE {
     ?cont      orkgp:HAS_EVALUATION      ?eval.
     ?eval      rdfs:label                ?eval_lbl.
      FILTER (str(?eval_lbl) = "F1-score")
     ?cont      orkg
