Question:
What evaluation metrics are commonly used when benchmarking models on the SciGEN dataset?

Generated SPARQL:
 SELECT DISTINCT?metric?metric_lbl
     WHERE {
      ?dataset       a                orkgc:Dataset;
                   rdfs:label      ?dataset_lbl.
       FILTER (str(?dataset_lbl) = "SciGEN")
      ?benchmark      orkgp:HAS_DATASET      ?dataset;
                      orkgp:HAS_EVALUATION   ?eval.
       OPTIONAL {?eval           orkgp:HAS_METRIC        ?metric.
               ?metric          rdfs:label              ?metric_lbl.}
       FILTER (str(?metric_lbl) = "F1", str(?metric_lbl) = "Accuracy", 
              str(?metric_lbl) = "AP", str(?metric_lbl) = "MCC", 
              str(?metric_lbl) = "Precision", str(?metric_lbl) = "Recall", 
              str(?metric_lbl) = "ROC_AUC")
      }<|eot_id|>
