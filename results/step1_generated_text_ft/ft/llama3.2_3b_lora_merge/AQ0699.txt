Question:
List the metrics that are used to evaluate models on the CommonsenseQA benchmark dataset?

Generated SPARQL:
 SELECT DISTINCT?metric?metric_lbl
    WHERE {
     ?dataset       a                orkgc:Dataset;
                      rdfs:label      ?dataset_lbl.
      FILTER (str(?dataset_lbl) = "CommonsenseQA")
     ?benchmark      orkgp:HAS_DATASET      ?dataset;
                      orkgp:HAS_EVALUATION   ?eval.
     ?eval           orkgp:HAS_METRIC        ?metric;
                      orkgp:HAS_VALUE         ?value.
     ?metric         rdfs:label              ?metric_lbl.
     ?cont          orkgp:HAS_BENCHMARK     ?benchmark;
                      orkgp:HAS_MODEL         ?model.
     ?model        rdfs:label              ?model_lbl.
     ?paper       orkgp:HAS_MODEL         ?model;
                  orkgp:HAS_SOURCE      ?source.
     ?source      rdfs:label              ?source_lbl.
     ?paper      orkgp:HAS_SOURCE      ?source;
                 orkgp:HAS_DOWNLOAD     ?download.
     ?download    rdfs:label              ?download_lbl.
     ?paper      orkgp:HAS_DOWNLOAD     ?download;
                 orkgp:HAS_VERSION      ?version.
     ?version    rdfs:label              ?version_lbl.
     ?paper      orkgp:HAS_VERSION      ?version;
                 orkgp:HAS_MODEL         ?model.
     ?model      rdfs:label              ?model_lbl.
     ?cont      orkgp:HAS_BENCHMARK     ?benchmark;
                 orkgp:HAS_EVALUATION   ?eval.
     ?eval      orkgp:HAS_VALUE         ?value;
                 rdfs:label              ?eval_lbl.
     ?eval      orkgp:HAS_METRIC        ?metric;
                 rdfs:label              ?metric_lbl.
     ?cont      rdfs:label              ?cont_lbl.
    } 6
    1 
    4 
    2 
    3 
    5 
    FILTER (str(?cont_lbl) = "CommonsenseQA")
    ORDER BY DESC(?value) 
    LIMIT 6
    Note: The dataset name is "CommonsenseQA", not "CommonsenseQA-benchmark" or "commonsenseqa". The dataset is correctly identified by its label, which is "CommonsenseQA". Therefore, the filtering should use the dataset label, not the dataset name.  As a side note, this is one of the many datasets in the ORKG that uses the same label for the dataset and the benchmark.  Also, note that the common sense question answering task is not a single task, but a collection of tasks, and the ORKG does not contain information about the tasks.  The filtering of the dataset label is used to identify the correct dataset. 
    If you have any questions or need further clarification, please let me know. 
    Note that the above SPARQL query can be optimized by joining the three tables and adding a filter to remove the irrelevant data. 
    Here is an optimized version of the SPARQL query.
    ```sql
    SELECT DISTINCT?metric?metric_lbl
    WHERE {
     ?dataset       a                orkgc:Dataset;
                      rdfs:label      ?dataset_lbl.
      FILTER (str(?dataset_lbl) = "CommonsenseQA")
     ?benchmark      orkgp:HAS_DATASET      ?dataset;
                      orkgp:HAS_EVALUATION   ?eval.
     ?eval           orkgp:HAS_METRIC        ?metric;
                      orkgp:HAS_VALUE         ?value.
     ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
     ?cont         rdfs:label              ?cont_lbl.
      FILTER (str(?cont_lbl) = "CommonsenseQA")
     ?cont         orkgp:HAS_EVALUATION   ?eval.
     ?cont         orkgp:HAS_VALUE         ?value;
                  orkgp:HAS_METRIC        ?metric.
     ?metric         rdfs:label              ?metric_lbl.
     ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
     ?cont         rdfs:label              ?cont_lbl.
     ?cont         orkgp:HAS_EVALUATION   ?eval.
     ?cont         orkgp:HAS_VALUE         ?value;
                  orkgp:
