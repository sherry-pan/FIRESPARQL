{
"question": "List the metrics that are used to evaluate models on the CommonsenseQA benchmark dataset?",
"extracted\_terms": {
"CommonsenseQA benchmark dataset",
"metrics",
"evaluate models"
},
"candidates": {
"CommonsenseQA benchmark dataset": [
{
"uri": "orkgr:R122689",
"rdfs:label": "CommonsenseQA",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgr:R122689",
"rdfs:label": "CommonsenseQA",
"rdf:type": "orkgc:Dataset"
},
{
"uri": "orkgp:HAS_DATASET",
"rdfs:label": "has dataset",
"rdf:type": "orkgp:Predicate"
}
],
"metrics": [
{
"uri": "orkgp:HAS_METRIC",
"rdfs:label": "has metric",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:ACCURACY",
"rdfs:label": "Accuracy",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgp:F1_SCORE",
"rdfs:label": "F1 Score",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgp:PRECISION",
"rdfs:label": "Precision",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgp:RECALL",
"rdfs:label": "Recall",
"rdf:type": "orkgc:Resource"
}
],
"evaluate models": [
{
"uri": "orkgp:HAS_EVALUATION",
"rdfs:label": "has evaluation",
"rdf:type": "orkgp:Predicate"
}
]
}
}