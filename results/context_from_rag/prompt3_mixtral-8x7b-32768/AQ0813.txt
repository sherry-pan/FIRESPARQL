{
"question": "What evaluation metrics are commonly used when benchmarking models on the SQuAD2.0 dataset?",
"extracted\_terms": {
"SQuAD2.0 dataset",
"evaluation metrics",
"benchmarking models"
},
"candidates": {
"SQuAD2.0 dataset": [
{
"uri": "orkgr:R122689",
"rdfs:label": "SQuAD2.0",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgr:R122689",
"rdfs:label": "SQuAD2.0",
"rdf:type": "orkgc:Dataset"
},
{
"uri": "orkgp:HAS_DATASET",
"rdfs:label": "has dataset",
"rdf:type": "orkgp:Predicate"
}
],
"evaluation metrics": [
{
"uri": "orkgp:HAS_EVALUATION_METRIC",
"rdfs:label": "has evaluation metric",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_F1_SCORE",
"rdfs:label": "has F1 score",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_ACCURACY",
"rdfs:label": "has accuracy",
"rdf:type": "orkgp:Predicate"
}
],
"benchmarking models": [
{
"uri": "orkgp:HAS_EVALUATION",
"rdfs:label": "has evaluation",
"rdf:type": "orkgp:Predicate"
},
{
"uri": "orkgp:HAS_MODEL",
"rdfs:label": "has model",
"rdf:type": "orkgp:Predicate"
}
]
}
}