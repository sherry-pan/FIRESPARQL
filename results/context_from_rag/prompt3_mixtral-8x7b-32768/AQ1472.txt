{
"question": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the TriviaQA dataset?",
"extracted\_terms": {
"top performing model",
"Accuracy score",
"benchmarked on",
"TriviaQA dataset"
},
"candidates": {
"top performing model": [
{
"uri": "orkgp:HAS\_MODEL",
"rdfs:label": "Top Performing Model",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgp:HAS\_MODEL",
"rdfs:label": "Top Performing Model",
"rdf:type": "orkgc:Model"
}
],
"Accuracy score": [
{
"uri": "orkgp:HAS\_SCORE",
"rdfs:label": "Accuracy Score",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgp:HAS\_SCORE",
"rdfs:label": "Accuracy Score",
"rdf:type": "orkgc:Metric"
}
],
"benchmarked on": [
{
"uri": "orkgp:HAS\_EVALUATION",
"rdfs:label": "Benchmarked On",
"rdf:type": "orkgc:Resource"
}
],
"TriviaQA dataset": [
{
"uri": "orkgr:R122689",
"rdfs:label": "TriviaQA",
"rdf:type": "orkgc:Resource"
},
{
"uri": "orkgr:R122689",
"rdfs:label": "TriviaQA",
"rdf:type": "orkgc:Dataset"
}
]
}
}