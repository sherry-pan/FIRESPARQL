{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from sciqa dataset\n",
    "### Read all.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Parse the JSON data\n",
    "data = json.loads(open('/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/sciqa/test/questions.json').read())\n",
    "\n",
    "# Extract the relevant fields and convert to DataFrame\n",
    "records = []\n",
    "for question in data['questions']:\n",
    "    id = question['id']\n",
    "    query_type = question['query_type']\n",
    "    question_text = question['question']  \n",
    "    paraphrased_question = question['paraphrased_question'] \n",
    "    query = question['query']\n",
    "    template_id = question['template_id']\n",
    "    auto_generated = question['auto_generated']\n",
    "    query_shape = question['query_shape']\n",
    "    query_class = question['query_class']\n",
    "    number_of_patterns = question['number_of_patterns']\n",
    "    records.append((id, query_type, question_text, paraphrased_question, query, template_id,\n",
    "                     auto_generated, query_shape, query_class, number_of_patterns))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records, columns=['id', 'query_type', 'question_text', 'paraphrased_question', 'query', 'template_id', \n",
    "                                    'auto_generated', 'query_shape', 'query_class', 'number_of_patterns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter all test questions and save it to a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>question_text</th>\n",
       "      <th>paraphrased_question</th>\n",
       "      <th>query</th>\n",
       "      <th>template_id</th>\n",
       "      <th>auto_generated</th>\n",
       "      <th>query_shape</th>\n",
       "      <th>query_class</th>\n",
       "      <th>number_of_patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQ1475</td>\n",
       "      <td>Factoid</td>\n",
       "      <td>{'string': 'Which model has achieved the highe...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?model ?model_lbl\n",
       "...</td>\n",
       "      <td>T05</td>\n",
       "      <td>True</td>\n",
       "      <td>Tree</td>\n",
       "      <td>WHICH-WHAT</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQ0495</td>\n",
       "      <td>Factoid</td>\n",
       "      <td>{'string': 'List the title and ID of research ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?paper ?paper_lbl\n",
       "...</td>\n",
       "      <td>T02</td>\n",
       "      <td>True</td>\n",
       "      <td>Tree</td>\n",
       "      <td>WHICH-WHAT</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ0176</td>\n",
       "      <td>Factoid</td>\n",
       "      <td>{'string': 'What models are being evaluated on...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?model ?model_lbl\n",
       "...</td>\n",
       "      <td>T01</td>\n",
       "      <td>True</td>\n",
       "      <td>Tree</td>\n",
       "      <td>WHICH-WHAT</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQ0392</td>\n",
       "      <td>Factoid</td>\n",
       "      <td>{'string': 'Provide a list of research paper t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?paper ?paper_lbl\n",
       "...</td>\n",
       "      <td>T02</td>\n",
       "      <td>True</td>\n",
       "      <td>Tree</td>\n",
       "      <td>WHICH-WHAT</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQ1059</td>\n",
       "      <td>non-factoid</td>\n",
       "      <td>{'string': 'What is the top benchmark score an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?metric ?metric_lb...</td>\n",
       "      <td>T04</td>\n",
       "      <td>True</td>\n",
       "      <td>Tree</td>\n",
       "      <td>WHICH-WHAT</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   query_type                                      question_text  \\\n",
       "0  AQ1475      Factoid  {'string': 'Which model has achieved the highe...   \n",
       "1  AQ0495      Factoid  {'string': 'List the title and ID of research ...   \n",
       "2  AQ0176      Factoid  {'string': 'What models are being evaluated on...   \n",
       "3  AQ0392      Factoid  {'string': 'Provide a list of research paper t...   \n",
       "4  AQ1059  non-factoid  {'string': 'What is the top benchmark score an...   \n",
       "\n",
       "  paraphrased_question                                              query  \\\n",
       "0                   []  {'sparql': 'SELECT DISTINCT ?model ?model_lbl\n",
       "...   \n",
       "1                   []  {'sparql': 'SELECT DISTINCT ?paper ?paper_lbl\n",
       "...   \n",
       "2                   []  {'sparql': 'SELECT DISTINCT ?model ?model_lbl\n",
       "...   \n",
       "3                   []  {'sparql': 'SELECT DISTINCT ?paper ?paper_lbl\n",
       "...   \n",
       "4                   []  {'sparql': 'SELECT DISTINCT ?metric ?metric_lb...   \n",
       "\n",
       "  template_id  auto_generated query_shape query_class  number_of_patterns  \n",
       "0         T05            True        Tree  WHICH-WHAT                  12  \n",
       "1         T02            True        Tree  WHICH-WHAT                   5  \n",
       "2         T01            True        Tree  WHICH-WHAT                   6  \n",
       "3         T02            True        Tree  WHICH-WHAT                   5  \n",
       "4         T04            True        Tree  WHICH-WHAT                  13  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_id = [i for i in df['id']]\n",
    "test_questions = [i['string'] for i in df['question_text']]\n",
    "test_query = [i['sparql'] for i in df['query']]\n",
    "test_df = pd.DataFrame({'id': question_id, 'question': test_questions, 'query': test_query})\n",
    "test_df.to_csv('xueli_data/sciqa/project_data/test_questions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from dblp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "data = json.loads(open('/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/dblp/test/questions.json').read())\n",
    "# Extract the relevant fields and convert to DataFrame\n",
    "records = []\n",
    "for question in data['questions']:\n",
    "    id = question['id']\n",
    "    query_type = question['query_type']\n",
    "    question_text = question['question']  \n",
    "    paraphrased_question = question['paraphrased_question'] \n",
    "    query = question['query']\n",
    "    template_id = question['template_id']\n",
    "    entities = question['entities']\n",
    "    relations = question['relations']\n",
    "    records.append((id, query_type, question_text, paraphrased_question, query, template_id,\n",
    "                     entities, relations))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records, columns=['id', 'query_type', 'question_text', 'paraphrased_question', 'query', 'template_id', \n",
    "                                    'entities', 'relations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>question_text</th>\n",
       "      <th>paraphrased_question</th>\n",
       "      <th>query</th>\n",
       "      <th>template_id</th>\n",
       "      <th>entities</th>\n",
       "      <th>relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q0001</td>\n",
       "      <td>SINGLE_FACT</td>\n",
       "      <td>{'string': 'Show the Wikidata ID of the person...</td>\n",
       "      <td>{'string': 'What is the Wikidata identifier of...</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?answer WHERE { &lt;h...</td>\n",
       "      <td>TC04</td>\n",
       "      <td>[&lt;https://dblp.org/pid/95/2265&gt;]</td>\n",
       "      <td>[&lt;https://dblp.org/rdf/schema#wikidata&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q0002</td>\n",
       "      <td>SINGLE_FACT</td>\n",
       "      <td>{'string': 'Which papers did the author Rodr\\u...</td>\n",
       "      <td>{'string': 'What are the papers written by the...</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?answer WHERE { ?a...</td>\n",
       "      <td>TC01</td>\n",
       "      <td>[&lt;https://dblp.org/pid/04/6636&gt;]</td>\n",
       "      <td>[&lt;https://dblp.org/rdf/schema#authoredBy&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q0003</td>\n",
       "      <td>SINGLE_FACT</td>\n",
       "      <td>{'string': 'What is the webpage of the person ...</td>\n",
       "      <td>{'string': 'Mention the webpage of the researc...</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?answer WHERE { &lt;h...</td>\n",
       "      <td>TC05</td>\n",
       "      <td>[&lt;https://dblp.org/pid/s/MohammadSoleymani&gt;]</td>\n",
       "      <td>[&lt;https://dblp.org/rdf/schema#webpage&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q0004</td>\n",
       "      <td>SINGLE_FACT</td>\n",
       "      <td>{'string': 'Which publications did Neamati, D....</td>\n",
       "      <td>{'string': 'What are the papers written by the...</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?answer WHERE { ?a...</td>\n",
       "      <td>TC01</td>\n",
       "      <td>[&lt;https://dblp.org/pid/304/4294&gt;]</td>\n",
       "      <td>[&lt;https://dblp.org/rdf/schema#authoredBy&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q0005</td>\n",
       "      <td>SINGLE_FACT</td>\n",
       "      <td>{'string': 'Which papers did the author Kawasa...</td>\n",
       "      <td>{'string': 'What are the papers written by Kaw...</td>\n",
       "      <td>{'sparql': 'SELECT DISTINCT ?answer WHERE { ?a...</td>\n",
       "      <td>TC01</td>\n",
       "      <td>[&lt;https://dblp.org/pid/08/4968&gt;]</td>\n",
       "      <td>[&lt;https://dblp.org/rdf/schema#authoredBy&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   query_type                                      question_text  \\\n",
       "0  Q0001  SINGLE_FACT  {'string': 'Show the Wikidata ID of the person...   \n",
       "1  Q0002  SINGLE_FACT  {'string': 'Which papers did the author Rodr\\u...   \n",
       "2  Q0003  SINGLE_FACT  {'string': 'What is the webpage of the person ...   \n",
       "3  Q0004  SINGLE_FACT  {'string': 'Which publications did Neamati, D....   \n",
       "4  Q0005  SINGLE_FACT  {'string': 'Which papers did the author Kawasa...   \n",
       "\n",
       "                                paraphrased_question  \\\n",
       "0  {'string': 'What is the Wikidata identifier of...   \n",
       "1  {'string': 'What are the papers written by the...   \n",
       "2  {'string': 'Mention the webpage of the researc...   \n",
       "3  {'string': 'What are the papers written by the...   \n",
       "4  {'string': 'What are the papers written by Kaw...   \n",
       "\n",
       "                                               query template_id  \\\n",
       "0  {'sparql': 'SELECT DISTINCT ?answer WHERE { <h...        TC04   \n",
       "1  {'sparql': 'SELECT DISTINCT ?answer WHERE { ?a...        TC01   \n",
       "2  {'sparql': 'SELECT DISTINCT ?answer WHERE { <h...        TC05   \n",
       "3  {'sparql': 'SELECT DISTINCT ?answer WHERE { ?a...        TC01   \n",
       "4  {'sparql': 'SELECT DISTINCT ?answer WHERE { ?a...        TC01   \n",
       "\n",
       "                                       entities  \\\n",
       "0              [<https://dblp.org/pid/95/2265>]   \n",
       "1              [<https://dblp.org/pid/04/6636>]   \n",
       "2  [<https://dblp.org/pid/s/MohammadSoleymani>]   \n",
       "3             [<https://dblp.org/pid/304/4294>]   \n",
       "4              [<https://dblp.org/pid/08/4968>]   \n",
       "\n",
       "                                    relations  \n",
       "0    [<https://dblp.org/rdf/schema#wikidata>]  \n",
       "1  [<https://dblp.org/rdf/schema#authoredBy>]  \n",
       "2     [<https://dblp.org/rdf/schema#webpage>]  \n",
       "3  [<https://dblp.org/rdf/schema#authoredBy>]  \n",
       "4  [<https://dblp.org/rdf/schema#authoredBy>]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_id = [i for i in df['id']]\n",
    "test_questions = [i['string'] for i in df['question_text']]\n",
    "test_query = [i['sparql'] for i in df['query']]\n",
    "test_df = pd.DataFrame({'id': question_id, 'question': test_questions, 'query': test_query})\n",
    "test_df.to_csv('/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/dblp/project_data/test_questions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read train_questions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Parse the JSON data\n",
    "data = json.loads(open('/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/sciqa/train/questions.json').read())\n",
    "\n",
    "# Extract the relevant fields and convert to DataFrame\n",
    "records = []\n",
    "for question in data['questions']:\n",
    "    id = question['id']\n",
    "    query_type = question['query_type']\n",
    "    question_text = question['question']  \n",
    "    paraphrased_question = question['paraphrased_question'] \n",
    "    query = question['query']\n",
    "    template_id = question['template_id']\n",
    "    auto_generated = question['auto_generated']\n",
    "    query_shape = question['query_shape']\n",
    "    query_class = question['query_class']\n",
    "    number_of_patterns = question['number_of_patterns']\n",
    "    records.append((id, query_type, question_text, paraphrased_question, query, template_id,\n",
    "                     auto_generated, query_shape, query_class, number_of_patterns))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records, columns=['id', 'query_type', 'question_text', 'paraphrased_question', 'query', 'template_id', \n",
    "                                    'auto_generated', 'query_shape', 'query_class', 'number_of_patterns'])\n",
    "question_id = [i for i in df['id']]\n",
    "test_questions = [i['string'] for i in df['question_text']]\n",
    "test_query = [i['sparql'] for i in df['query']]\n",
    "test_df = pd.DataFrame({'id': question_id, 'question': test_questions, 'query': test_query})\n",
    "test_df.to_csv('/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/sciqa/project_data/train_questions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: sentence-transformers in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scipy in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sentence-transformers scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherrypan/miniconda3/envs/llama-factory/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding train questions...\n",
      "Encoding test questions and finding most similar train question...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:21<00:00, 24.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to most_similar_questions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load CSV files\n",
    "test_df = pd.read_csv(\"/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/sciqa/project_data/test_questions.csv\")\n",
    "train_df = pd.read_csv(\"/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/sciqa/project_data/train_questions.csv\")\n",
    "\n",
    "# Load Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Small, fast, and good quality\n",
    "\n",
    "# Encode all questions using Sentence-BERT\n",
    "print(\"Encoding train questions...\")\n",
    "train_embeddings = model.encode(train_df[\"question\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "print(\"Encoding test questions and finding most similar train question...\")\n",
    "results = []\n",
    "\n",
    "# Iterate through each test question\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    test_id = row[\"id\"]\n",
    "    test_question = row[\"question\"]\n",
    "    test_query = row[\"query\"]\n",
    "\n",
    "    # Encode test question\n",
    "    test_embedding = model.encode(test_question, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    cosine_scores = cosine_similarity([test_embedding.cpu().numpy()], train_embeddings.cpu().numpy())[0]\n",
    "\n",
    "    # Find index of best match\n",
    "    best_match_idx = np.argmax(cosine_scores)\n",
    "\n",
    "    # Get best matched train question and query\n",
    "    best_train_question = train_df.iloc[best_match_idx][\"question\"]\n",
    "    best_train_query = train_df.iloc[best_match_idx][\"query\"]\n",
    "\n",
    "    results.append({\n",
    "        \"id\": test_id,\n",
    "        \"test_question\": test_question,\n",
    "        \"test_query\": test_query,\n",
    "        \"best_train_question\": best_train_question,\n",
    "        \"train_query\": best_train_query\n",
    "    })\n",
    "\n",
    "# Save results to CSV\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv(\"/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/sciqa/project_data/most_similar_questions.csv\", index=False)\n",
    "print(\"Saved to most_similar_questions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
