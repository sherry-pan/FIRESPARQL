Question:
What evaluation metrics are commonly used when benchmarking models on the MultiRC dataset?

Generated SPARQL:
 PREFIX ork: <http://purl.org/linked-data/ork#>
     SELECT?metric
     WHERE {
    ?metric ork:hasMetric "MultiRC".
    ?metric ork:hasMetric "f1".
    ?metric ork:hasMetric "accuracy".
    ?metric ork:hasMetric "accuracy@k".
    ?metric ork:hasMetric "ROUGE".
    ?metric ork:hasMetric "ROUGE@k".
    ?metric ork:hasMetric "EM".
    ?metric ork:hasMetric "EM@k".
     }<|eot_id|>
