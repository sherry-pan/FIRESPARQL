Question:
What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?

Generated SPARQL:
PREFIX orkg: <http://orkg.org/orkg/>

SELECT?metric
WHERE {
 ?model a orkg:Model.
 ?model orkg:HAS_EVALUATION?evaluation.
 ?evaluation orkg:HAS_BENCHMARK?benchmark.
 ?benchmark orkg:HAS_DATASET?dataset.
 ?dataset orkg:NAME "MLDoc Zero-Shot English-to-Italian".
 ?evaluation orkg:HAS_METRIC?metric.
}<|eot_id|>
