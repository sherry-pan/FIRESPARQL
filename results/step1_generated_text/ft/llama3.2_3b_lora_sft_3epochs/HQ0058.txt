Question:
What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request? 

Generated SPARQL:
 SELECT DISTINCT?metric?metric_lbl (SUM(?value) AS?score)
     WHERE {
         {
             SELECT?metric?metric_lbl?value
             WHERE {
                ?paper rdf:type orkgc:Paper.
                ?paper rdfs:label?title.
                ?paper orkgp:P30?algorithm.
                ?algorithm rdfs:label?algorithm_lbl.
                ?paper orkgp:P31?feature.
                ?feature rdfs:label?feature_lbl.
                ?feature orkgp:P32?eval.
                ?eval rdfs:label?eval_lbl.
                ?eval orkgp:P33?metric.
                 BIND(xsd:float(?value) AS?value)
                 FILTER(REGEX(STR(?title), "feature request")
                 and
                 (str(?algorithm_lbl) = "naive bayes"
                 and
                 (str(?feature_lbl) = "machine learning" and
                 str(?eval_lbl) = "bag of words" and
                 str(?metric_lbl) = "precision"
                 or
                 str(?metric_lbl) = "recall"
                 or
                 str(?metric_lbl) = "f1"))
             }
             ORDER BY DESC(?value)
         }
         UNION
         {
             SELECT?metric?metric_lbl?value
             WHERE {
                ?paper rdf:type orkgc:Paper.
                ?paper rdfs:label?title.
                ?paper orkgp:P30?algorithm.
                ?algorithm rdfs:label?algorithm_lbl.
                ?paper orkgp:P31?feature.
                ?feature rdfs:label?feature_lbl.
                ?feature orkgp:P32?eval.
                
