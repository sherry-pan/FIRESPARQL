Question:
What is the best performing model benchmarking the 200k Short Texts for Humor Detection dataset in terms of F1-score metric?

Generated SPARQL:
 SELECT DISTINCT?model?model_lbl
     WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label      ?dataset_lbl.
       FILTER (str(?dataset_lbl    = "200k Short Texts for Humor Detection")
               &&?dataset       a                orkgc:Dataset)
      ?benchmark      orkgp:HAS_DATASET      ?dataset;
                      orkgp:HAS_EVALUATION   ?eval.
      ?eval           orkgp:HAS_VALUE        ?value;
                      orkgp:HAS_METRIC        ?metric.
      ?metric         rdfs:label              ?metric_lbl.
       BIND(xsd:float(?value) AS?value_lbl)
      ?benchmark      orkgp:HAS_MODEL         ?model;
                      orkgp:HAS_EVALUATION   ?eval.
      ?model       rdfs:label              ?model_lbl.
      ?eval           orkgp:HAS_VALUE        ?value.
       BIND(
         IF(?metric_lbl    = "F1-score",
             xsd:float(?value_lbl) AS?f1)
       AS?f1_lbl)
       FILTER(?f1       > 0.9)
     }<|eot_id|>
