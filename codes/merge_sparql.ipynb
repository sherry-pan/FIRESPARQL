{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4064b6",
   "metadata": {},
   "source": [
    "### merge sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60f107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 合并完成，保存路径：/Users/sherrypan/GitHub/LLaMa-Factory/results/step5_error_analysis/sparql_results_with_queries.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# 定义文件路径\n",
    "results_csv_path = Path(\"/Users/sherrypan/GitHub/LLaMa-Factory/results/step3_sparql_running_against_orkg/ft/llama3_8b_lora_sft_15epochs_round1/sparql_results.csv\")\n",
    "sparql_dir = Path(\"/Users/sherrypan/GitHub/LLaMa-Factory/results/step2_clean_sparql/ft/llama3_8b_lora_sft_15epochs_round1\")\n",
    "test_questions_path = Path(\"/Users/sherrypan/GitHub/LLaMa-Factory/xueli_data/sciqa/project_data/test_questions.csv\")\n",
    "\n",
    "# 加载两个 CSV 文件\n",
    "results_df = pd.read_csv(results_csv_path)\n",
    "test_questions_df = pd.read_csv(test_questions_path)\n",
    "\n",
    "# 将 test_questions_df 设置为以 id 为索引，便于查找\n",
    "test_questions_df.set_index(\"id\", inplace=True)\n",
    "\n",
    "# 初始化新的列\n",
    "sparql_queries = []\n",
    "question_strings = []\n",
    "ground_truth_sparqls = []\n",
    "\n",
    "# 遍历每一个 question_id\n",
    "for question_id in results_df[\"question_id\"]:\n",
    "    # 读取 SPARQL 查询文件\n",
    "    sparql_file = sparql_dir / f\"{question_id}.txt\"\n",
    "    if sparql_file.exists():\n",
    "        with open(sparql_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            sparql_query = f.read().strip()\n",
    "    else:\n",
    "        sparql_query = \"\"\n",
    "\n",
    "    sparql_queries.append(sparql_query)\n",
    "\n",
    "    # 从 test_questions.csv 中取出 question 和 query 字段\n",
    "    if question_id in test_questions_df.index:\n",
    "        question_strings.append(test_questions_df.loc[question_id, \"question\"])\n",
    "        ground_truth_sparqls.append(test_questions_df.loc[question_id, \"query\"])\n",
    "    else:\n",
    "        question_strings.append(\"\")\n",
    "        ground_truth_sparqls.append(\"\")\n",
    "\n",
    "# 添加新列\n",
    "results_df[\"gen_sparql\"] = sparql_queries\n",
    "results_df[\"question_string\"] = question_strings\n",
    "results_df[\"gt_sparql\"] = ground_truth_sparqls\n",
    "\n",
    "# 保存为新 CSV 文件（避免覆盖原文件）\n",
    "output_path = \"/Users/sherrypan/GitHub/LLaMa-Factory/results/step5_error_analysis/sparql_results_with_queries.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ 合并完成，保存路径：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef0c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
