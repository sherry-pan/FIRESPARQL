Question:
What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?

Generated SPARQL:
 SELECT?eval_metric?eval_metric_lbl
     WHERE {
      ?dataset       a            orkgc:Dataset;
                      rdfs:label      ?dataset_lbl.
       FILTER (str(?dataset_lbl) = "MLDoc Zero-Shot English-to-Italian")
      ?benchmark      orkgp:HAS_DATASET      ?dataset;
                      orkgp:HAS_EVALUATION   ?eval.
       OPTIONAL {?eval           orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
               ?eval_metric      rdfs:label              ?eval_metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
       OPTIONAL {?cont      orkgp:HAS_EVALUATION     ?eval.
               ?eval         orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
               ?eval_metric  rdfs:label              ?eval_metric_lbl.}
     }```SPARQL
```sql
SELECT?eval_metric?eval_metric_lbl
WHERE {
 ?dataset       a            orkgc:Dataset;
                 rdfs:label      ?dataset_lbl.
  FILTER (str(?dataset_lbl) = "MLDoc Zero-Shot English-to-Italian")
 ?benchmark      orkgp:HAS_DATASET      ?dataset;
                 orkgp:HAS_EVALUATION   ?eval.
  OPTIONAL {?eval           orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric      rdfs:label              ?eval_metric_lbl.}
 ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
  OPTIONAL {?cont      orkgp:HAS_EVALUATION     ?eval.
          ?eval         orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric  rdfs:label              ?eval_metric_lbl.}
}
```SPARQL
```sql
SELECT?eval_metric?eval_metric_lbl
WHERE {
 ?dataset       a            orkgc:Dataset;
                 rdfs:label      ?dataset_lbl.
  FILTER (str(?dataset_lbl) = "MLDoc Zero-Shot English-to-Italian")
 ?benchmark      orkgp:HAS_DATASET      ?dataset;
                 orkgp:HAS_EVALUATION   ?eval.
  OPTIONAL {?eval           orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric      rdfs:label              ?eval_metric_lbl.}
 ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
  OPTIONAL {?cont      orkgp:HAS_EVALUATION     ?eval.
          ?eval         orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric  rdfs:label              ?eval_metric_lbl.}
}
```SPARQL
```sql
SELECT?eval_metric?eval_metric_lbl
WHERE {
 ?dataset       a            orkgc:Dataset;
                 rdfs:label      ?dataset_lbl.
  FILTER (str(?dataset_lbl) = "MLDoc Zero-Shot English-to-Italian")
 ?benchmark      orkgp:HAS_DATASET      ?dataset;
                 orkgp:HAS_EVALUATION   ?eval.
  OPTIONAL {?eval           orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric      rdfs:label              ?eval_metric_lbl.}
 ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
  OPTIONAL {?cont      orkgp:HAS_EVALUATION     ?eval.
          ?eval         orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric  rdfs:label              ?eval_metric_lbl.}
}
```SPARQL
```sql
SELECT?eval_metric?eval_metric_lbl
WHERE {
 ?dataset       a            orkgc:Dataset;
                 rdfs:label      ?dataset_lbl.
  FILTER (str(?dataset_lbl) = "MLDoc Zero-Shot English-to-Italian")
 ?benchmark      orkgp:HAS_DATASET      ?dataset;
                 orkgp:HAS_EVALUATION   ?eval.
  OPTIONAL {?eval           orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric      rdfs:label              ?eval_metric_lbl.}
 ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
  OPTIONAL {?cont      orkgp:HAS_EVALUATION     ?eval.
          ?eval         orkgp:HAS_EVALUATION_METRIC  ?eval_metric.
          ?eval_metric  rdfs:label              ?eval_metric_lbl.}
}
```SPARQL
```sql
SELECT?eval_metric?eval_metric_lbl
WHERE {
 ?dataset       a            orkgc:Dataset;
                 rdfs:label      ?dataset_lbl.
  FILTER (str(?dataset_lbl) = "MLDoc Zero-Shot English-to-Italian")
 ?benchmark     
