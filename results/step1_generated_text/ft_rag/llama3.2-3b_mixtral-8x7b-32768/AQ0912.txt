Question:
What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?

Generated SPARQL:
 ```sql
SELECT?metric?metric_lbl
WHERE {
  orkgp:R123456 orkgp:HAS_DATASET, orkgp:HAS_DATASET
 ?dataset?dataset_lbl
  FILTER(REGEX(?dataset_lbl, "MLDoc Zero-Shot English-to-Italian"))
 ?dataset orkgp:HAS_EVALUATION_METRIC, orkgp:HAS_EVALUATION_METRIC
 ?metric?metric_lbl
}
``` 
    This SPARQL query can be executed on the ORKG to get the evaluation metrics used in the benchmarking of the MLDoc Zero-Shot English-to-Italian dataset. 
    The query works as follows:
    1. It selects the evaluation metric and its label.
    2. It starts from the dataset (represented by orkgp:R123456) and filters out datasets that do not contain the phrase "MLDoc Zero-Shot English-to-Italian".
    3. For
