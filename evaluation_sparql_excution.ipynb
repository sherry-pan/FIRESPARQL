{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "def process_sparql_result(raw_result: str):\n",
    "    \"\"\"\n",
    "    Process SPARQL SELECT result string:\n",
    "    1. Remove variable names (header row).\n",
    "    2. Extract and clean data rows into a set of tuples.\n",
    "    \"\"\"\n",
    "    # Step 1: Split by line\n",
    "    try:\n",
    "        lines = raw_result.strip().split('\\n')\n",
    "    except:\n",
    "        # print(\"Error: Unable to split the result string into lines.\")\n",
    "        # return an empty set if the input is not a valid string\n",
    "        return set()\n",
    "\n",
    "    # Step 2: Remove the first line (variable names)\n",
    "    data_lines = lines[1:] if lines[0].startswith('?') else lines\n",
    "\n",
    "    result_set = set()\n",
    "    for line in data_lines:\n",
    "        # Split by tab\n",
    "        columns = line.strip().split('\\t')\n",
    "\n",
    "        # Clean RDF literal suffixes like ^^<http://...>\n",
    "        cleaned_columns = [\n",
    "            col.split('^^')[0] if '^^' in col else col\n",
    "            for col in columns\n",
    "        ]\n",
    "\n",
    "        # Add as tuple to set\n",
    "        result_set.add(tuple(cleaned_columns))\n",
    "\n",
    "    return result_set\n",
    "\n",
    "\n",
    "# define a function to compare the content of two rows with row names \"message\" and \"gt_message\"\n",
    "def get_exact_match(file):\n",
    "    \"\"\"\"\n",
    "    \"Compare the content of two rows with row names \"message\" and \"gt_message\"\n",
    "    if they are the same, EM = 1,\n",
    "    if they are different, EM = 0\n",
    "    return the average EM value\n",
    "    \"\"\"\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"The number of all sparql queries is {len(df)}\")\n",
    "\n",
    "    # filter the dataframe to only include rows where the status is \"SUCCESS\", and create a new dataframe\n",
    "    df_success = df[df['status'] == 'SUCCESS'].copy()\n",
    "    print(f\"Then number of the SUCCESS sparql queries is {len(df_success)}\")\n",
    "\n",
    "    # compare each row with the gt_message\n",
    "    df_success['EM'] = df_success.apply(lambda row: 1 if process_sparql_result(row['message']) == process_sparql_result(row['gt_message']) else 0, axis=1)\n",
    "    \n",
    "    # print the average EM value for all the SUCCESS queries\n",
    "    average_em_success_set = df_success['EM'].mean()\n",
    "    print(f\"The average EM value for all the SUCCESS sparql queries is {average_em_success_set}\")\n",
    "    # print the average EM value for all the queries\n",
    "    average_em_test_set = df_success['EM'].sum()/ len(df)\n",
    "    print(f\"The average EM value for all the test sparql queries is {average_em_test_set}\")\n",
    "    success_ids = df_success['question_id'][df_success['EM'] == 1]\n",
    "    # save the ids to a file\n",
    "    with open(\"success_ids.txt\", \"w\") as f:\n",
    "        for id in success_ids:\n",
    "            f.write(f\"{id}\\n\")\n",
    "    return average_em_success_set, average_em_test_set\n",
    "\n",
    "\n",
    "def relaxed_exact_match(test_set1, ref_set2, threshold=0.5):\n",
    "    intersection = test_set1 & ref_set2\n",
    "    if len(ref_set2) == 0:\n",
    "        overlap_ratio = 0\n",
    "        return 0, overlap_ratio\n",
    "    overlap_ratio = len(intersection) / len(ref_set2)\n",
    "    if overlap_ratio >= threshold:\n",
    "        return 1, overlap_ratio\n",
    "    else:\n",
    "        return 0, overlap_ratio\n",
    "    \n",
    "\n",
    "def get_relaxed_exact_match(file, theshold=0.5):\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(file)\n",
    "    # print(f\"The number of all sparql queries is {len(df)}\")\n",
    "\n",
    "    # filter the dataframe to only include rows where the status is \"SUCCESS\", and create a new dataframe\n",
    "    df_success = df[df['status'] == 'SUCCESS'].copy()\n",
    "    # print(f\"Then number of the SUCCESS sparql queries is {len(df_success)}\")\n",
    "\n",
    "    # compare each row, create set for the gt_message and the message\n",
    "    for i in range(len(df_success)):\n",
    "        # create a set for the gt_message\n",
    "        gt_set = process_sparql_result(df_success.iloc[i]['gt_message'])\n",
    "        # create a set for the message\n",
    "        message_set = process_sparql_result(df_success.iloc[i]['message'])\n",
    "        # compare the two sets, if they are the same, EM = 1, if they are different, EM = 0\n",
    "        df_success.loc[i, \"relaxed_EM\"] = relaxed_exact_match(message_set, gt_set, theshold)[0]\n",
    "        df_success.loc[i, 'overlap_ratio'] = relaxed_exact_match(message_set, gt_set, theshold)[1]\n",
    "\n",
    "    # print the average EM value for all the SUCCESS queries\n",
    "    average_em_success_set = df_success['relaxed_EM'].mean()\n",
    "    # print(f\"The average relaxed EM value for all the SUCCESS sparql queries is {average_em_success_set}\")\n",
    "    # print the average EM value for all the queries\n",
    "    average_em_test_set = df_success['relaxed_EM'].sum()/ len(df)\n",
    "    # print(f\"The average relaxed EM value for all the test sparql queries is {average_em_test_set}\")\n",
    "    # get the ids of the queries with relaxed_EM = 1\n",
    "    success_ids = df_success['question_id'][df_success['relaxed_EM'] == 1]\n",
    "    # save the ids to a file\n",
    "    with open(\"success_ids.txt\", \"w\") as f:\n",
    "        for id in success_ids:\n",
    "            f.write(f\"{id}\\n\")\n",
    "    return average_em_success_set, average_em_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of all sparql queries is 513\n",
      "Then number of the SUCCESS sparql queries is 195\n",
      "The average EM value for all the SUCCESS sparql queries is 0.7897435897435897\n",
      "The average EM value for all the test sparql queries is 0.3001949317738791\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# read the results in csv file\n",
    "file = \"results/step3_sparql_running_against_orkg/ft/llama3.2_3b_lora_terminal/retrieved_results.csv\"\n",
    "em = get_exact_match(file)\n",
    "# df_success_em.head(1)['message'].values[0] # print the first message\n",
    "print(\"####################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the theshold from 0 to 1, with step 0.1\n",
    "theshold_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "relaxed_em_success_lst = []\n",
    "relaxed_em_test_lst = []\n",
    "for theshold in theshold_lst:\n",
    "    # get the relaxed exact match\n",
    "    average_em_success_set, average_em_test_set = get_relaxed_exact_match(file, theshold=theshold)\n",
    "    relaxed_em_success_lst.append(average_em_success_set)\n",
    "    relaxed_em_test_lst.append(average_em_test_set)\n",
    "    # print(f\"The average relaxed EM value for all the SUCCESS sparql queries with theshold {theshold} is {average_em_success_set}\")\n",
    "    # print(f\"The average relaxed EM value for all the test sparql queries with theshold {theshold} is {average_em_test_set}\")\n",
    "\n",
    "print(\"relatexd_em_success_lst: \", relaxed_em_success_lst)\n",
    "print(\"relatexd_em_test_lst: \", relaxed_em_test_lst)\n",
    "# plot the results with relatexd_em_success_lst\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Set the x-axis values\n",
    "x = theshold_lst\n",
    "# Set the y-axis values\n",
    "y1 = relaxed_em_success_lst\n",
    "# Set the color of the line\n",
    "color1 = 'blue'\n",
    "# Plot the first line\n",
    "plt.plot(x, y1, color=color1, label='relaxed EM for SUCCESS queries')\n",
    "# show the point values on the line, round to 2 decimal places\n",
    "plt.scatter(x, y1, color=color1)\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Relaxed Exact Match for SUCCESS queries')\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Overlap Threshold')\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Relaxed Exact Match')\n",
    "# Set the x-axis ticks\n",
    "plt.xticks(np.arange(0.1, 1.1, 0.1))\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6707317073170732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "330/492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39227642276422764"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "193/492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03333333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
