Question:
Where can I find code references in papers that have used the All-attention network - 18 layers model for benchmarking purposes?

Generated SPARQL:
 SELECT?code
     WHERE {
      ?model       a            orkgc:Model;
                   rdfs:label   ?model_lbl.
       FILTER (str(?model_lbl) = "All-attention network - 18 layers")
      ?benchmark      orkgp:HAS_DATASET       ?dataset.
      ?cont           orkgp:HAS_BENCHMARK     ?benchmark.
      ?cont           orkgp:HAS_MODEL         ?model;
                       orkgp:HAS_SOURCE_CODE   ?code.
     } ORDER BY DESC(?code) LIMIT 5. 
     ``` 

    {
      "query": "SELECT?code\nWHERE {\n ?model       a            orkgc:Model;\n                  rdfs:label   ?model_lbl.\n  FILTER (str(?model_lbl) = \"All-attention network - 18 layers\")\n ?benchmark      orkgp:HAS_DATASET       ?dataset.\n ?cont           orkgp:HAS_BENCHMARK     ?benchmark.\n ?cont           orkgp:HAS_MODEL         ?model;\n                  orkgp:HAS_SOURCE_CODE   ?code.\n} ORDER BY DESC(?code) LIMIT 5."
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 
    } 

