Question:
Can you provide the highest benchmark result, including the metric and score, for the Natural Questions (long) dataset?

Generated SPARQL:
 SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score)
     WHERE {
      ?dataset       a                orkgc:Dataset;
                       rdfs:label      ?dataset_lbl.
       FILTER (str(?dataset_lbl) = "Natural Questions (long)")
      ?benchmark      orkgp:HAS_DATASET      ?dataset;
                       orkgp:HAS_EVALUATION   ?eval.
       OPTIONAL {?eval           orkgp:HAS_METRIC        ?metric.
               ?metric          rdfs:label              ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK     ?benchmark;
                     orkgp:HAS_SCORE         ?score_value.
       OPTIONAL {?score_value       orkgp:HAS_VALUE        ?value.
               ?value            orkgp:P71080           ?value_lbl.
                FILTER (xsd:double(?value_lbl) > 0.8)}
      ?cont         orkgp:P71066             ?number_of_type.
      ?number_of_type    rdfs:label             ?number_of_type_lbl.
       FILTER (str(?number_of_type_lbl) = "test")
     }
     ORDER BY DESC(?score)<|eot_id|>
