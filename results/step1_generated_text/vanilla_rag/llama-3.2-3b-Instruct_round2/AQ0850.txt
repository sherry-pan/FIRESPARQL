Question:
What evaluation metrics are commonly used when benchmarking models on the TempEval-3 dataset?

Generated SPARQL:
 PREFIX orkg: <http://orkg.org/orkg/>
     SELECT?metric
     WHERE {
    ?metric orkg:HAS_EVALUATION?e.
    ?e orkg:HAS_BENCHMARK?benchmark.
     FILTER (bn:label = "TempEval-3" )
    ?metric orkg:HAS_LABEL?m.
     FILTER (str:label = "accuracy" OR str:label = "recall" OR str:label = "micro-F1" OR str:label = "macro-F1" OR str:label = "NDCG@10")
     }<|eot_id|>
