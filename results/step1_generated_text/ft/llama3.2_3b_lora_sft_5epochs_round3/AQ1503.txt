Question:
What is the best performing model benchmarking the Supervised: dataset in terms of SemEval 2013 metric?

Generated SPARQL:
 SELECT DISTINCT?model?model_lbl
     WHERE {
        ?dataset       a                orkgc:Dataset;
                     rdfs:label      ?dataset_lbl.
         FILTER (str(?dataset_lbl) = "Supervised:")
        ?benchmark      orkgp:HAS_DATASET      ?dataset;
                         orkgp:HAS_EVALUATION   ?eval.
        ?eval           orkgp:HAS_VALUE        ?value;
                         rdfs:label              ?eval_lbl.
        ?benchmark      orkgp:HAS_MODEL         ?model.
        ?model        rdfs:label              ?model_lbl.
        ?cont         orkgp:HAS_BENCHMARK     ?benchmark.
        ?paper         orkgc:HAS_SOURCE        ?cont.
        ?paper         orkgp:HAS_MODEL         ?model.
        ?paper      rdfs:label              ?paper_lbl.
        ?eval         orkgp:HAS_METRIC         ?metric.
        ?metric      rdfs:label              ?metric_lbl.
         FILTER (str(?metric_lbl) = "SemEval 2013")
        ?value         orkgp:HAS_VALUE        ?value.
         BIND(xsd:float(?value) AS?value)
        ?cont         orkgp:HAS_MODEL         ?model.
        ?cont         rdfs:label              ?cont_lbl.
         BIND(xsd:float(?cont_lbl) AS?cont)
     }
     ORDER BY DESC(?value)
     LIMIT 10<|eot_id|>
