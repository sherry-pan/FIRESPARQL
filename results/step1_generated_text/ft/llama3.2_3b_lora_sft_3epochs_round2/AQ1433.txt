Question:
Indicate the model that performed best in terms of BLEU score metric on the WMT2016 English-German benchmark dataset?

Generated SPARQL:
 SELECT DISTINCT?model?model_lbl
     WHERE {
      ?metric     a       orkgc:Metric;
                 rdfs:label ?metric_lbl.
       FILTER (str(?metric_lbl      = "BLEU score")
               || str(?metric_lbl      = "ROUGE-N")
               || str(?metric_lbl      = "ROUGE-L")
               || str(?metric_lbl      = "ROUGE-W")
               || str(?metric_lbl      = "METEOR")
               || str(?metric_lbl      = "CIDEr")
               || str(?metric_lbl      = "CIDEr-SU")
               || str(?metric_lbl      = "BLEU")
               || str(?metric_lbl      = "Automatic Post-processing")
               || str(?metric_lbl      = "Bleu-04")
               || str(?metric_lbl      = "Bleu-08")
               || str(?metric_lbl      = "Bleu-12")
               || str(?metric_lbl      = "Bleu-16")
               || str(?metric_lbl      = "Bleu-20")
               || str(?metric_lbl      = "Bleu-24")
               || str(?metric_lbl      = "Bleu-28")
               || str(?metric_lbl      = "Bleu-32")
               || str(?metric_lbl      = "Bleu-36")
               || str(?metric_lbl      = "Bleu-40")
               || str(?metric_lbl      = "Bleu-44")
               || str(?metric_lbl      = "Bleu-48")
               || str(?metric_lbl      = "Bleu-52")
               || str(?metric_lbl      = "Bleu-56")
               ||
