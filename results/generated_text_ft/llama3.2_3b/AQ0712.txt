Question:
List the metrics that are used to evaluate models on the SciTLDR benchmark dataset?

Generated SPARQL:
 PREFIX orkg: <http://www.openresearch.org/ontology/orkg#>
     PREFIX wot: <http://www.wot semantics.org/ontology/wot#>
     SELECT?metric
     WHERE {
      ?metric orkg:metricType?mtType.
      ?metric orkg:evaluationMetric?em.
       FILTER (?em OR kg:dataset "SciTLDR"^^xsd:string).
      ?metric orkg:evaluationMetric?em2.
       FILTER (?em =?em2).
      ?metric orkg:metricName?metricName.
       SERVICE orkg:dataset "SciTLDR" { BIND ((?metric orkg:metricType?mtType) AS?metricType) }
     } 
     GROUP BY?metric
     HAVING (COUNT(?metric) >= 2)
     ORDER BY DESC
     LIMIT 1
    Note: The ORKG contains the following metrics: 
    - AUC-ROC
    - Area under the curve
    - Brier score
    - Mean squared error
    - Mean absolute error
    - Mean absolute percentage error
    - Mean squared logarithmic error
    - Precision
    - Recall
    - R squared
    - Root mean squared percentage error
    - Top-k accuracy
    - Zero-one loss
    The ORKG also contains the following metrics for text classification, 
    - Accuracy
    - Area under the curve
    - F1 score
    - Macro F1 score
    - Mean average precision
    - Mean recall
    - Micro F1 score
    - Precision
    - Recall
    - Specificity
    - True negative rate
    - True positive rate
    - Weighted average precision
    - Weighted average recall
    - Weighted F1 score
    - Zero-one loss
    The ORKG also contains the metrics for multi-class classification, 
    - Accuracy
    - Area under the curve
    - F1 score
    - Macro F1 score
    - Mean average precision
    - Mean recall
    - Precision
    - Recall
    - Specificity
    - True negative rate
    - True positive rate
    - Weighted average precision
    - Weighted average recall
    - Weighted F1 score
    - Zero-one loss
    ORKG contains the metrics for regression, 
    - Mean absolute error
    - Mean absolute percentage error
    - Mean squared error
    - Mean squared logarithmic error
    - Root mean squared percentage error
    - R squared
    - Zero-one loss
    ORKG contains the metrics for sentiment analysis, 
    - Accuracy
    - Area under the curve
    - F1 score
    - Macro F1 score
    - Mean average precision
    - Mean recall
    - Precision
    - Recall
    - Specificity
    - True negative rate
    - True positive rate
    - Weighted average precision
    - Weighted average recall
    - Weighted F1 score
    - Zero-one loss
    ORKG contains the metrics for text classification, 
    - Accuracy
    - Area under the curve
    - F1 score
    - Macro F1 score
    - Mean average precision
    - Mean recall
    - Precision
    - Recall
    - Specificity
    - True negative rate
    - True positive rate
    - Weighted average precision
    - Weighted average recall
    - Weighted F1 score
    - Zero-one loss
    ORKG contains the metrics for multi-class classification, 
    - Accuracy
    - Area under the curve
    - F1 score
    - Macro F1 score
    - Mean average precision
    - Mean recall
    - Precision
    - Recall
    - Specificity
    - True negative rate
    - True positive rate
    - Weighted average precision
    - Weighted average recall
    - Weighted F1 score
    - Zero-one loss
    ORKG contains the metrics for regression, 
    - Mean absolute error
    - Mean absolute percentage error
    - Mean squared error
    - Mean squared logarithmic error
    - Root mean squared percentage error
    - R squared
    - Zero-one loss
    ORKG contains the metrics for
